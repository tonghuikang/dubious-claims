{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StanfordIE requires Python2. Text cleaning seems to be easier in Python3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert article text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = u\"\"\"This is a multiline string. \n",
    "This can contain many sentences.\n",
    "Clean this text afterward. \n",
    "Can load from a text file also. Obama is born in Kenya. \n",
    "\n",
    "Lee Hsien Loong’s decision to leave Halimah Yacob is open to speculation, but this appears to be passive racism. The Singapore Prime Minister nonetheless need to be questioned, like whether if he perceives Halimah Yacob’s hijab a poor representation to Singapore.\n",
    "\n",
    "There are hard questions to ask about Halimah Yacob as well. Like whether if she needs an English translator when speaking with other English-speakers, or whether if she takes direct instruction from Lee Hsien Loong as a puppet many believe her to be.\n",
    "\n",
    "S$1.54 million-a-year for reading essay. How much further useless can Halimah Yacob get?\n",
    "\n",
    "With her eyes glued on the scripts, Indian-turned-Malay President Halimah Yacob obediently read on live TV her first speech in Parliament as Singapore President. The “independent” President’s speech, written by the PAP Ministers, is as best a load of hot air, waxing lyrical about leadership, equality, meritocracy and a “bright future”.\n",
    "\n",
    "Halimah Yacob is a puppet President appointed by Prime Minister Lee Hsien Loong. With Lee Hsien Loong’s control over the Election Department, her two opponent contestants were disqualified giving her a walkover.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def replacing(text):  # not implement, but needed for the quotations and the apostrophes \n",
    "    # remove annoying characters\n",
    "    chars = {\n",
    "        '\\xc2\\x82' : ',',        # High code comma\n",
    "        '\\xc2\\x84' : ',,',       # High code double comma\n",
    "        '\\xc2\\x85' : '...',      # Tripple dot\n",
    "        '\\xc2\\x88' : '^',        # High carat\n",
    "        '\\xc2\\x91' : '\\x27',     # Forward single quote\n",
    "        '\\xc2\\x92' : '\\x27',     # Reverse single quote\n",
    "        '\\xc2\\x93' : '\\x22',     # Forward double quote\n",
    "        '\\xc2\\x94' : '\\x22',     # Reverse double quote\n",
    "        '\\xc2\\x95' : ' ',\n",
    "        '\\xc2\\x96' : '-',        # High hyphen\n",
    "        '\\xc2\\x97' : '--',       # Double hyphen\n",
    "        '\\xc2\\x99' : ' ',\n",
    "        '\\xc2\\xa0' : ' ',\n",
    "        '\\xc2\\xa6' : '|',        # Split vertical bar\n",
    "        '\\xc2\\xab' : '<<',       # Double less than\n",
    "        '\\xc2\\xbb' : '>>',       # Double greater than\n",
    "        '\\xc2\\xbc' : '1/4',      # one quarter\n",
    "        '\\xc2\\xbd' : '1/2',      # one half\n",
    "        '\\xc2\\xbe' : '3/4',      # three quarters\n",
    "        '\\xca\\xbf' : '\\x27',     # c-single quote\n",
    "        '\\xcc\\xa8' : '',         # modifier - under curve\n",
    "        '\\xcc\\xb1' : '',         # modifier - under line\n",
    "        '\\u2019' : '\\x27'\n",
    "    }\n",
    "\n",
    "    def replace_chars(match):\n",
    "        char = match.group(0)\n",
    "        return chars[char]\n",
    "\n",
    "    return re.sub('(' + '|'.join(chars.keys()) + ')', replace_chars, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = replacing(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a multiline string.', 'This can contain many sentences.', 'Clean this text afterward.', 'Can load from a text file also.', 'Obama is born in Kenya.', 'Lee Hsien Loongs decision to leave Halimah Yacob is open to speculation, but this appears to be passive racism.', 'The Singapore Prime Minister nonetheless need to be questioned, like whether if he perceives Halimah Yacobs hijab a poor representation to Singapore.', 'There are hard questions to ask about Halimah Yacob as well.', 'Like whether if she needs an English translator when speaking with other English-speakers, or whether if she takes direct instruction from Lee Hsien Loong as a puppet many believe her to be.', 'S$1.54 million-a-year for reading essay.', 'How much further useless can Halimah Yacob get?', 'With her eyes glued on the scripts, Indian-turned-Malay President Halimah Yacob obediently read on live TV her first speech in Parliament as Singapore President.', 'The independent Presidents speech, written by the PAP Ministers, is as best a load of hot air, waxing lyrical about leadership, equality, meritocracy and a bright future.', 'Halimah Yacob is a puppet President appointed by Prime Minister Lee Hsien Loong.', 'With Lee Hsien Loongs control over the Election Department, her two opponent contestants were disqualified giving her a walkover.']\n"
     ]
    }
   ],
   "source": [
    "# article_text = clean(article_text) # to implement with some package from nltk to remove non standard characters.\n",
    "# article_text = split_into_sentences(article_text) \n",
    "\n",
    "import nltk\n",
    "\n",
    "article_text_list = nltk.sent_tokenize(article_text)\n",
    "\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "for i, sentence in enumerate(article_text_list):\n",
    "#     regex = re.compile('[%s]' % re.escape(string.punctuation)) #see documentation here: http://docs.python.org/2/library/string.html\n",
    "    article_text_list[i] = re.sub(r'[^\\x00-\\x7f]',r'', sentence).encode('ascii', 'ignore')\n",
    "    \n",
    "    \n",
    "print(article_text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading list of dubious claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dubious_claims_list = [\"This is a list of dubious claims.\", \"Obama is born in Kenya\", \"President Halimah is a puppet.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting information from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a multiline string.\n",
      "[['This', ' is', ' multiline'], ['This', ' is', ' multiline string'], ['This', ' is', ' string']]\n",
      "This can contain many sentences.\n",
      "[['This', ' can contain', ' sentences'], ['This', ' can contain', ' many sentences']]\n",
      "Clean this text afterward.\n",
      "[]\n",
      "Can load from a text file also.\n",
      "[]\n",
      "Obama is born in Kenya.\n",
      "[['Obama', ' is born in', ' Kenya'], ['Obama', ' is', ' born']]\n",
      "Lee Hsien Loongs decision to leave Halimah Yacob is open to speculation, but this appears to be passive racism.\n",
      "[['this', ' appears', ' racism'], ['Lee Hsien Loongs decision', ' is open to', ' speculation'], ['Lee Hsien Loongs decision', ' is', ' open'], ['Lee Hsien Loongs decision', ' leave', ' Halimah Yacob'], ['this', ' be', ' racism'], ['this', ' be', ' passive racism'], ['this', ' appears', ' passive racism']]\n",
      "The Singapore Prime Minister nonetheless need to be questioned, like whether if he perceives Halimah Yacobs hijab a poor representation to Singapore.\n",
      "[['Singapore Prime Minister', ' nonetheless need', ' questioned'], ['Singapore Prime Minister', ' need', ' questioned'], ['Singapore Prime Minister', ' be', ' questioned']]\n",
      "There are hard questions to ask about Halimah Yacob as well.\n",
      "[['hard questions', ' ask about', ' Halimah Yacob'], ['hard questions', ' ask about', ' Halimah Yacob'], ['questions', ' ask about', ' Halimah Yacob'], ['questions', ' ask about', ' Halimah Yacob']]\n",
      "Like whether if she needs an English translator when speaking with other English-speakers, or whether if she takes direct instruction from Lee Hsien Loong as a puppet many believe her to be.\n",
      "[]\n",
      "S.54 million-a-year for reading essay.\n",
      "[]\n",
      "How much further useless can Halimah Yacob get?\n",
      "[['Halimah Yacob', ' can get', ' much further useless'], ['Halimah Yacob', ' can get', ' How much further useless'], ['Halimah Yacob', ' can get', ' useless'], ['Halimah Yacob', ' can get', ' much useless'], ['Halimah Yacob', ' can get', ' How much useless'], ['Halimah Yacob', ' can get', ' further useless']]\n",
      "With her eyes glued on the scripts, Indian-turned-Malay President Halimah Yacob obediently read on live TV her first speech in Parliament as Singapore President.\n",
      "[['her eyes', ' glued on', ' scripts'], ['Indian-turned-Malay President Halimah Yacob', ' obediently read on', ' live TV'], ['Indian-turned-Malay President Halimah Yacob', ' read on', ' live TV'], ['Indian-turned-Malay President Halimah Yacob', ' read on', ' TV'], ['her first speech', ' is in', ' Parliament as Singapore President'], ['Indian-turned-Malay President Halimah Yacob', ' obediently read on', ' TV']]\n",
      "The independent Presidents speech, written by the PAP Ministers, is as best a load of hot air, waxing lyrical about leadership, equality, meritocracy and a bright future.\n",
      "[['independent Presidents speech', ' written by', ' PAP Ministers'], ['Presidents speech', ' is as', ' load hot air'], ['Presidents speech', ' is as', ' best load of hot air waxing'], ['independent Presidents speech', ' is as', ' load of hot air'], ['speech', ' is', ' best'], ['Presidents speech', ' is as', ' load hot air waxing'], ['independent Presidents speech', ' is as', ' best load hot air waxing'], ['Presidents speech', ' is as', ' load of hot air waxing'], ['independent Presidents speech', ' is as', ' best load of hot air'], ['Presidents speech', ' written by', ' PAP Ministers'], ['Presidents speech', ' is as', ' best load hot air waxing'], ['Presidents speech', ' is as', ' best load hot air'], ['independent Presidents speech', ' is as', ' load hot air'], ['Presidents speech', ' is as', ' load of hot air'], ['independent Presidents speech', ' is as', ' best load hot air'], ['independent Presidents speech', ' is as', ' best load of hot air waxing'], ['independent Presidents speech', ' is as', ' load hot air waxing'], ['independent Presidents speech', ' is as', ' load of hot air waxing'], ['Presidents speech', ' is as', ' best load of hot air']]\n",
      "Halimah Yacob is a puppet President appointed by Prime Minister Lee Hsien Loong.\n",
      "[['Halimah Yacob', ' is', ' puppet President'], ['Halimah Yacob', ' is', ' puppet President appointed'], ['Halimah Yacob', ' is', ' puppet President appointed by Prime Minister Lee Hsien Loong']]\n",
      "With Lee Hsien Loongs control over the Election Department, her two opponent contestants were disqualified giving her a walkover.\n",
      "[['her opponent contestants', ' were disqualified With', ' Lee Hsien Loongs control over Election Department'], ['her opponent contestants', ' giving', ' her walkover'], ['her two opponent contestants', ' giving', ' her walkover'], ['her opponent contestants', ' were', ' disqualified'], ['her two opponent contestants', ' were', ' disqualified'], ['her opponent contestants', ' were disqualified With', ' Lee Hsien Loongs control'], ['her two opponent contestants', ' were disqualified With', ' Lee Hsien Loongs control over Election Department'], ['her two opponent contestants', ' were disqualified With', ' Lee Hsien Loongs control']]\n",
      "[[['This', ' is', ' multiline'], ['This', ' is', ' multiline string'], ['This', ' is', ' string']], [['This', ' can contain', ' sentences'], ['This', ' can contain', ' many sentences']], [], [], [['Obama', ' is born in', ' Kenya'], ['Obama', ' is', ' born']], [['this', ' appears', ' racism'], ['Lee Hsien Loongs decision', ' is open to', ' speculation'], ['Lee Hsien Loongs decision', ' is', ' open'], ['Lee Hsien Loongs decision', ' leave', ' Halimah Yacob'], ['this', ' be', ' racism'], ['this', ' be', ' passive racism'], ['this', ' appears', ' passive racism']], [['Singapore Prime Minister', ' nonetheless need', ' questioned'], ['Singapore Prime Minister', ' need', ' questioned'], ['Singapore Prime Minister', ' be', ' questioned']], [['hard questions', ' ask about', ' Halimah Yacob'], ['hard questions', ' ask about', ' Halimah Yacob'], ['questions', ' ask about', ' Halimah Yacob'], ['questions', ' ask about', ' Halimah Yacob']], [], [], [['Halimah Yacob', ' can get', ' much further useless'], ['Halimah Yacob', ' can get', ' How much further useless'], ['Halimah Yacob', ' can get', ' useless'], ['Halimah Yacob', ' can get', ' much useless'], ['Halimah Yacob', ' can get', ' How much useless'], ['Halimah Yacob', ' can get', ' further useless']], [['her eyes', ' glued on', ' scripts'], ['Indian-turned-Malay President Halimah Yacob', ' obediently read on', ' live TV'], ['Indian-turned-Malay President Halimah Yacob', ' read on', ' live TV'], ['Indian-turned-Malay President Halimah Yacob', ' read on', ' TV'], ['her first speech', ' is in', ' Parliament as Singapore President'], ['Indian-turned-Malay President Halimah Yacob', ' obediently read on', ' TV']], [['independent Presidents speech', ' written by', ' PAP Ministers'], ['Presidents speech', ' is as', ' load hot air'], ['Presidents speech', ' is as', ' best load of hot air waxing'], ['independent Presidents speech', ' is as', ' load of hot air'], ['speech', ' is', ' best'], ['Presidents speech', ' is as', ' load hot air waxing'], ['independent Presidents speech', ' is as', ' best load hot air waxing'], ['Presidents speech', ' is as', ' load of hot air waxing'], ['independent Presidents speech', ' is as', ' best load of hot air'], ['Presidents speech', ' written by', ' PAP Ministers'], ['Presidents speech', ' is as', ' best load hot air waxing'], ['Presidents speech', ' is as', ' best load hot air'], ['independent Presidents speech', ' is as', ' load hot air'], ['Presidents speech', ' is as', ' load of hot air'], ['independent Presidents speech', ' is as', ' best load hot air'], ['independent Presidents speech', ' is as', ' best load of hot air waxing'], ['independent Presidents speech', ' is as', ' load hot air waxing'], ['independent Presidents speech', ' is as', ' load of hot air waxing'], ['Presidents speech', ' is as', ' best load of hot air']], [['Halimah Yacob', ' is', ' puppet President'], ['Halimah Yacob', ' is', ' puppet President appointed'], ['Halimah Yacob', ' is', ' puppet President appointed by Prime Minister Lee Hsien Loong']], [['her opponent contestants', ' were disqualified With', ' Lee Hsien Loongs control over Election Department'], ['her opponent contestants', ' giving', ' her walkover'], ['her two opponent contestants', ' giving', ' her walkover'], ['her opponent contestants', ' were', ' disqualified'], ['her two opponent contestants', ' were', ' disqualified'], ['her opponent contestants', ' were disqualified With', ' Lee Hsien Loongs control'], ['her two opponent contestants', ' were disqualified With', ' Lee Hsien Loongs control over Election Department'], ['her two opponent contestants', ' were disqualified With', ' Lee Hsien Loongs control']]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle \n",
    "\n",
    "# output should be a list of three element list.\n",
    "# [['Barack Obama', ' was', ' born'], ['Barack Obama', ' was born in', ' Hawaii']]\n",
    "\n",
    "# article_claims = stanfordIE(article_text)\n",
    "\n",
    "article_claims = []\n",
    "\n",
    "for sentence in article_text_list[:]:\n",
    "    os.system(\"echo \\\"{}\\\" > Stanford-OpenIE-Python/samples2.txt\".format(sentence))\n",
    "    !cat Stanford-OpenIE-Python/samples2.txt\n",
    "    os.system(\"python Stanford-OpenIE-Python/main.py -f samples2.txt -o out5.txt\")\n",
    "    with open(\"out5.txt\", \"rb\") as fp:   # Unpickling\n",
    "        b = pickle.load(fp)\n",
    "        print(b)\n",
    "        article_claims.append(b)\n",
    "        \n",
    "print(article_claims)\n",
    "\n",
    "# todo: combine them into one step to reduce loading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dubious_claims = []\n",
    "\n",
    "for sentence in dubious_claims_list[:2]:\n",
    "    os.system(\"echo \\\"{}\\\" > Stanford-OpenIE-Python/samples.txt\".format(sentence))\n",
    "    !cat Stanford-OpenIE-Python/samples.txt\n",
    "    os.system(\"python Stanford-OpenIE-Python/main.py -f samples.txt -o out2.txt -g\")\n",
    "    with open(\"out2.txt\", \"rb\") as fp:   # Unpickling\n",
    "        b = pickle.load(fp)\n",
    "        print(b)\n",
    "        dubious_claims.append(b)\n",
    "        \n",
    "print(dubious_claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_of_SIF_similarity = SIF_compare(article_claims,dubious_claims)\n",
    "plt.imshow(matrix_of_SIF_similarity)\n",
    "# label x and y labels with the claims in fine print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_of_InferSent_similarity = SIF_compare(article_claims,dubious_claims)\n",
    "plt.imshow(matrix_of_InferSent_similarity)\n",
    "# label x and y labels with the claims in fine print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('SIF/src')\n",
    "import data_io, params, SIF_embedding\n",
    "\n",
    "# input\n",
    "wordfile = 'SIF/data/glove.840B.300d.txt' # word vector file, can be downloaded from GloVe website\n",
    "weightfile = 'SIF/auxiliary_data/enwiki_vocab_min200.txt' # each line is a word and its frequency\n",
    "weightpara = 1e-3 # the parameter in the SIF weighting scheme, usually in the range [3e-5, 3e-3]\n",
    "rmpc = 1 # number of principal components to remove in SIF weighting scheme\n",
    "sentences = ['this is an example sentence', 'this is another sentence that is slightly longer']\n",
    "\n",
    "# load word vectors\n",
    "(words, We) = data_io.getWordmap(wordfile)\n",
    "\n",
    "# load word weights\n",
    "word2weight = data_io.getWordWeight(weightfile, weightpara) # word2weight['str'] is the weight for the word 'str'\n",
    "weight4ind = data_io.getWeight(words, word2weight) # weight4ind[i] is the weight for the i-th word\n",
    "\n",
    "# load sentences\n",
    "x, m = data_io.sentences2idx(sentences, words) # x is the array of word indices, m is the binary mask indicating whether there is a word in that location\n",
    "w = data_io.seq2weight(x, m, weight4ind) # get word weights\n",
    "# https://github.com/PrincetonML/SIF/issues/25\n",
    "\n",
    "# set parameters\n",
    "paramsz = params.params()\n",
    "paramsz.rmpc = rmpc\n",
    "# get SIF embedding\n",
    "embeddings = SIF_embedding.SIF_embedding(We, x, w, paramsz) # embedding[i,:] is the embedding for sentence i\n",
    "# print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in pairs:\n",
    "    sentences = pair\n",
    "    # load sentences\n",
    "    x, m = data_io.sentences2idx(sentences, words) # x is the array of word indices, m is the binary mask indicating whether there is a word in that location\n",
    "    w = data_io.seq2weight(x, m, weight4ind) # get word weights\n",
    "    # https://github.com/PrincetonML/SIF/issues/25\n",
    "    \n",
    "    # set parameters\n",
    "    paramsz = params.params()\n",
    "    paramsz.rmpc = rmpc\n",
    "    # get SIF embedding\n",
    "    embeddings = SIF_embedding.SIF_embedding(We, x, w, paramsz) # embedding[i,:] is the embedding for sentence i\n",
    "#     print(embeddings)\n",
    "    print(pair)\n",
    "    print(np.dot(embeddings[0], embeddings[1]))\n",
    "#     print(np.dot(embeddings[0], embeddings[1])/(np.linalg.norm(embeddings[0])*np.linalg.norm(embeddings[1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
